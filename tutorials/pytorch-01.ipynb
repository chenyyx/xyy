{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch 实现线性回归\n",
    "\n",
    "上一篇教程中，我们基本介绍了 pytorch 里面的操作单元，Tensor，以及计算图中的操作单位 Variable，相信大家都已经熟悉了。\n",
    "\n",
    "今天这一部分，我们从这两个最基本的机器学习，线性回归以及 Logistic 回归来开始建立我们的计算图并进行计算。\n",
    "\n",
    "由于我们本次介绍的主要是 pytorch 的教程，所以每个算法的太多数学背景以及推导过程就不再细讲了，需要的同学可以自己找相应的教材去了解。  \n",
    "比如《统计学习方法》，《PRML》，周志华的《西瓜书》以及《机器学习实战》都可以了解到相应的内容。\n",
    "\n",
    "## 1、线性回归\n",
    "\n",
    "对于线性回归，我们这里简单地介绍一下一元线性回归。即给出一系列的点，找一条线，使得这条直线与这些点的距离之和最小。\n",
    "![线性回归](img/pt_lr_1.jpg)\n",
    "上面这张图就简单地描述了线性回归的基本原理，下面我们重点讲讲如何用 pytorch 写一个简单的线性回归。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 引入第三方库\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1、数据\n",
    "首先我们需要给出一系列的点作为线性回归的数据，使用 numpy 来存储这些点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nABJEuANAggh3AEjQ/wHPvMMZocznHgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa019390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train = np.array([[3.3], [4.4], [5.5], [6.71], [6.93], [4.168],\n",
    "                    [9.779], [6.182], [7.59], [2.167], [7.042],\n",
    "                    [10.791], [5.313], [7.997], [3.1]], dtype=np.float32)\n",
    "\n",
    "y_train = np.array([[1.7], [2.76], [2.09], [3.19], [1.694], [1.573],\n",
    "                    [3.366], [2.596], [2.53], [1.221], [2.827],\n",
    "                    [3.465], [1.65], [2.904], [1.3]], dtype=np.float32)\n",
    "\n",
    "# 将数据点展示出来\n",
    "def data_plot(data, label):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)  # add_subplot(349)函数的参数的意思是，将画布分成3行4列图像画在从左到右从上到下第9块\n",
    "    ax.scatter([data[:].flatten()],[label.T[:].flatten()])  # scatter 的x是 features，y是 label\n",
    "    plt.show()\n",
    "\n",
    "data_plot(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还记得 pytorch 里面的基本处理单元吗？ Tensor ，我们需要将 numpy 转换成 Tensor ，如果你还记得上一节的内容，那么你一定知道怎么转换，也就是这个函数 torch.from_numpy()\n",
    "\n",
    "就像这样："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 将 numpy 的 array 转换成为 Tensor\n",
    "x_tensor = torch.from_numpy(x_train)\n",
    "y_tensor = torch.from_numpy(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这样，我们的数据就转换成了 Tensor 。也就便于我们接下来的处理了。\n",
    "\n",
    "### 1.2、模型\n",
    "我们上一节讲了基本的模型框架，那么我们这一节就按照这个基本的框架来写出一个线性回归模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        # 设置 线性回归\n",
    "        self.linear = nn.Linear(1, 1)  # 输入和输出都是 1 维的\n",
    "    # 定义前向传播函数，其实就是输出如何输出\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里的 nn.Linear() 表示的是 y = w * x + b ，里面的两个参数都是 1，表示的是 x 是 1 维的，y 也是 1 维的。当然这里是可以根据你想要的输入输出维度来更改的，之前使用的别的框架的同学应该对这里也比较熟悉吧。\n",
    "\n",
    "### 1.3、损失函数和优化器\n",
    "模型定义完成了，接下来就是需要定义 loss 和 optimizer ，就是误差和优化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里使用的是最小二乘 loss，之后我们做分类问题更多的使用的是 cross entropy loss，交叉熵。优化函数使用的是随机梯度下降，注意需要将 model 的参数 model.parameters() 传进去让这个函数知道它要优化的参数是哪些。\n",
    "\n",
    "### 1.4、训练\n",
    "该定义的都已经定义完成了，那我们开始训练吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anacondapy3.6\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[20/1000], loss: 1.012389\n",
      "Epoch[40/1000], loss: 0.880243\n",
      "Epoch[60/1000], loss: 0.786731\n",
      "Epoch[80/1000], loss: 0.720524\n",
      "Epoch[100/1000], loss: 0.673615\n",
      "Epoch[120/1000], loss: 0.640344\n",
      "Epoch[140/1000], loss: 0.616712\n",
      "Epoch[160/1000], loss: 0.599893\n",
      "Epoch[180/1000], loss: 0.587888\n",
      "Epoch[200/1000], loss: 0.579286\n",
      "Epoch[220/1000], loss: 0.573090\n",
      "Epoch[240/1000], loss: 0.568593\n",
      "Epoch[260/1000], loss: 0.565298\n",
      "Epoch[280/1000], loss: 0.562852\n",
      "Epoch[300/1000], loss: 0.561007\n",
      "Epoch[320/1000], loss: 0.559586\n",
      "Epoch[340/1000], loss: 0.558466\n",
      "Epoch[360/1000], loss: 0.557557\n",
      "Epoch[380/1000], loss: 0.556798\n",
      "Epoch[400/1000], loss: 0.556146\n",
      "Epoch[420/1000], loss: 0.555569\n",
      "Epoch[440/1000], loss: 0.555045\n",
      "Epoch[460/1000], loss: 0.554559\n",
      "Epoch[480/1000], loss: 0.554099\n",
      "Epoch[500/1000], loss: 0.553659\n",
      "Epoch[520/1000], loss: 0.553232\n",
      "Epoch[540/1000], loss: 0.552815\n",
      "Epoch[560/1000], loss: 0.552405\n",
      "Epoch[580/1000], loss: 0.552001\n",
      "Epoch[600/1000], loss: 0.551599\n",
      "Epoch[620/1000], loss: 0.551201\n",
      "Epoch[640/1000], loss: 0.550804\n",
      "Epoch[660/1000], loss: 0.550409\n",
      "Epoch[680/1000], loss: 0.550016\n",
      "Epoch[700/1000], loss: 0.549623\n",
      "Epoch[720/1000], loss: 0.549231\n",
      "Epoch[740/1000], loss: 0.548840\n",
      "Epoch[760/1000], loss: 0.548449\n",
      "Epoch[780/1000], loss: 0.548059\n",
      "Epoch[800/1000], loss: 0.547670\n",
      "Epoch[820/1000], loss: 0.547281\n",
      "Epoch[840/1000], loss: 0.546892\n",
      "Epoch[860/1000], loss: 0.546504\n",
      "Epoch[880/1000], loss: 0.546116\n",
      "Epoch[900/1000], loss: 0.545728\n",
      "Epoch[920/1000], loss: 0.545342\n",
      "Epoch[940/1000], loss: 0.544955\n",
      "Epoch[960/1000], loss: 0.544569\n",
      "Epoch[980/1000], loss: 0.544183\n",
      "Epoch[1000/1000], loss: 0.543798\n"
     ]
    }
   ],
   "source": [
    "# 设置迭代次数\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    inputs = Variable(x_tensor)\n",
    "    target = Variable(y_tensor)\n",
    "\n",
    "    # 前向传播\n",
    "    out = model(inputs) \n",
    "    loss = criterion(out, target) # 计算loss\n",
    "    # 反向传播\n",
    "    optimizer.zero_grad() # 梯度归零\n",
    "    loss.backward() # 反向传播\n",
    "    optimizer.step() # 更新参数\n",
    "\n",
    "    if (epoch+1) % 20 == 0:\n",
    "        print('Epoch[{}/{}], loss: {:.6f}'.format(epoch+1,num_epochs,loss.data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一个循环表示每个 epoch，接着开始前向传播，然后计算 loss，然后反向传播，接着优化函数，特别注意的是，在每次方向传播的时候需要将参数的梯度归零，即\n",
    "```python\n",
    "optimzier.zero_grad()\n",
    "```\n",
    "### 1.5、验证\n",
    "训练完成后，我们就可以开始测试模型了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.71657908]\n",
      " [ 1.26995254]\n",
      " [ 1.82332587]\n",
      " [ 2.43203688]\n",
      " [ 2.5427115 ]\n",
      " [ 1.15324116]\n",
      " [ 3.97594905]\n",
      " [ 2.1664176 ]\n",
      " [ 2.87473559]\n",
      " [ 0.14660442]\n",
      " [ 2.59905481]\n",
      " [ 4.48505211]\n",
      " [ 1.72925258]\n",
      " [ 3.07948375]\n",
      " [ 0.61596572]]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predict = model(Variable(x_tensor))\n",
    "predict_np = predict.data.numpy()\n",
    "print(predict_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特别注意的是，需要用 model.eval() ，让 model 变成测试模式，这主要是对 dropout 和 batch normalization 的操作在训练和测试的时候是不一样的。\n",
    "\n",
    "我们使用 matplotlib 再次将图形画出来，来看一下对比照。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAGjJJREFUeJzt3Xd4VFX6B/DvSwIkdJBICcRQA1JC\nJCAsSJcE4gq69pV11RVXUbEsSkAFASWKq+Lq6rKIZVXUHwvqivQiYAkEQpMuhC5NQ4eE5Pz+SLhy\nJ22SzJ1zy/fzPD5yDsPMy4R8OZw5972ilAIRETlHBd0FEBFR6TC4iYgchsFNROQwDG4iIodhcBMR\nOQyDm4jIYRjcREQOw+AmInIYBjcRkcOEWvGkdevWVdHR0VY8NRGRK61evfqoUirCn8daEtzR0dFI\nS0uz4qmJiFxJRHb7+1hulRAROQyDm4jIYRjcREQOw+AmInIYBjcRkcMwuImIHIbBTUTkMAxuIqJy\nys7JxeSF27H72OmgvJ4lF+AQEXnF3I0H8dcP1wAAQkMEw3o3t/w1GdxERGVwNisHcePn41x2LgCg\nV0wEHuzVLCivzeAmIiqlT1buwciZG4zxvEd7IKZ+9aC9PoObiMhPx89kI3bcfGN8U8dGePnm2KDX\nweAmIvLDW0t/wotztxjj5U/2RuM6VbTUwuAmIirG4RPn0PmFRcb4rz2bYeSAVhorYnATERVp/Feb\n8M6KXcZ41eh+iKheWWNFeRjcREQ+dh87jZ6Tlhrj0QNb474eTfUV5IPBTUR0ieGfpOOLtQeM8fqx\n/VEjrKLGigpicBMRAdh04AQGvr7cGE+6qT1ujm+ssaKiMbiJyNOUUrjj36n4fucxAED1sFCsGt0P\nYRVDNFdWNAY3EXnWyl2/4JZ/fW+M//2neFx7ZT2NFfmHwU1EnnMhJxcDJi/H9sOnAADNIqpi3qM9\nEBrijL57DG4i8pSFmw7hLx+kGeNPhnZBl6aXaayo9BjcROQJ57JzcPULi3D8bDYAoEvTOph+XxeI\niObKSo/BTUSu99/V+/DE/60zxrMf6Y42DWtqrKh8GNxE5Fonz2Wj3djfmkJdH9sQr98ep7GiwGBw\nE5ErTV2+ExNmbzbGS//WC9F1q2qsKHAY3ETkKkdPnUf8hIXG+O5u0Rjz+zYaKwo8v4NbREIApAHY\nr5S6zrqSiIjK5qW5W/DPpT8Z49RRfVGvRpjGiqxRmhX3cACbAdSwqBYiojLZ9+sZdH9xiTEekRAT\nlHs/6uJXcItIIwBJAJ4H8LilFRERlcJTM9bj07S9xnjds/1Rs4q9mkIFmr8r7tcAPAmgyJuqichQ\nAEMBICoqqvyVEREVY9m2I/jTtJXG+IUb2uGOq72RPSUGt4hcB+CwUmq1iPQq6nFKqSkApgBAfHy8\nCliFRESXUEqhSfLXxrhSaAWsffZaVKnknbMW/lyY3w3A9SKSAeATAH1E5ENLqyIiKsS0FbtMoX1d\n+wbYNmGAp0Ib8GPFrZRKBpAMAPkr7r8ppe60uC4iIkN2Ti5ajJ5jmts0LsFzgX2RN3/XROQYE77a\nhKmX3PfRDjfr1a1Uwa2UWgpgqSWVEBFd4vT5C2gzZp5pbsfzAxzTetVKXHETke3c/580zPvxkDEe\nP6gNhnSN1leQzTC4icg2jpw8j07PLzTN7Zo40JGtV63E4CYiW+j/6jfYduiUMX77zo5IbFtfY0X2\nxeAmIq12HjmFPn//xjSXkZKkqRpnYHATkTbNRn2NnNzfrteb8deuiI+uo7EiZ2BwE1HQpe/5FTf8\n8zvTHFfZ/mNwE1FQRY+cbRovfLwnml9eTVM1zsTgJqKg8L27evRlVbB0RG+NFTkXg5uILOXbFAoA\nVo7qi8tdeIODYGFwE5FlPk7dg1GzNhjj3jERePfuzhorcgcGNxEFXE6uQrNR5lX2hrH9UT3M3Tc4\nCBYGNxEF1Cvzt+L1xTuM8V1dr8Bzg9pqrMh9GNxEFBDnsnPQ6pm5prltEwagUiibQgUag5uIyu3x\nT9diZvp+Y5w8oBXu79lMY0XuxuAmojL79XQW4sYvMM2xKZT1GNxEVCY3/PNbpO/JNMaTb+uAQR0i\nNVbkHQxuIiqVvb+cwTUvLTHNef1y9c/T92PSvK04kHkWDWuFY0RCDAbHWfeXGIObiPwW+9x8HD+b\nbYw//svV+F3zuhor0u/z9P1InrkBZ7NzAAD7M88ieWbe2XWrwpsf9xJRiTbuP47okbNNoZ2RkuT5\n0AaASfO2GqF90dnsHEyat9Wy1+SKm4iK5dsUas7wa9C6QQ1N1djPgcyzpZoPBAY3ERVq+fYjGPLO\nSmNct1plpD3dT2NFvwn2nnJxGtYKx/5CQrphrXDLXpPBTUQF+K6yvx3ZB5EWBlFp6NhTLs6IhBhT\nPQAQXjEEIxJiLHtN7nETkWHmmn2m0O7cpA4yUpJsE9qAnj3l4gyOi8TEG9shslY4BEBkrXBMvLEd\nT5UQkbVycxWa+jSFWvdsf9SsYr+mUDr2lEsyOC4yqKt9rriJPO7NJTtMoX1zx0bISEmyZWgDRe8d\nW7mnbDdccRN51PkLOYh52twUasv4RIRVDNFUkX907CnbDYObyINGzdqAj1P3GOPH+rXE8H4tNFbk\nv4tbEnY5VaIDg5vIQ06cy0b7sfNNcz+9MBAhFZzVFCrYe8p2w+Amgr3OBVvlzqmpWLHjqDF+6Q/t\ncUunxhororJicJPn2e1ccKD9fPwcukxcZJpj61VnY3CT5xV3Ltjpwd0tZbHpqr537+6E3jGXa6yI\nAoHBTZ5nx3PB5bXt0En0f3WZac7rrVfdhMFNnqej14SVfC9X//KhbmjfqJamasgKvACHPG9EQgzC\nfc4uO/FccOrOY6bQDqtYARkpSQxtF+KKmzzPDeeCfVfZ34zohSsuq6qpGrIag5sIzj0X/NrCbXht\n4XZj3KZhDcx+5BqNFVEwlBjcIhIGYBmAyvmPn6GUGmN1YURUNKUUmiSbm0KtfrofLqtWWVNFFEz+\nrLjPA+ijlDolIhUBrBCROUqpHyyujYgK8cj0dHy57oAxFgF2TeSJES8pMbiVUgrAqfxhxfz/lJVF\nEVFBhTWFWjemP2qG27OLH1nHrz1uEQkBsBpAcwBvKqVSLa2KiEwSXl2GrYdOGuO2kTXw1cPcy/Yq\nv4JbKZUDoIOI1AIwS0TaKqU2XvoYERkKYCgAREVFBbxQIi/KPJOFDuMWmOa2TRiASqE8yetlpTpV\nopTKFJGlABIBbPT5uSkApgBAfHw8t1KIysn3iN8frmqEv98Sa4y90BiLCufPqZIIANn5oR0OoB+A\nFy2vjMij9hw7gx6TlpjmfJtCub0xFhXPnxV3AwDv5+9zVwDwmVLqK2vLIvIm31X2iIQYDOvdvMDj\n3NwYi0rmz6mS9QDiglALkWet3v0L/vDW96a54ppCubExFvmPV04SlUEg95d9V9mTb+uAQR2Kfy63\nNcai0uFH00SldHF/eX/mWSj8tr/8efr+Uj3Pu9/uKhDaGSlJJYY24J7GWFQ2XHETlVIg9pd9A/tf\nQzoioU19v2twQ2MsKjsGtwvwWFhwlWd/OXnmBkxfucc0V9YbHDi1MRaVH4Pb4XgsLPjKsr9cWFOo\nrx7ujraRNQNeH7kf97gdrrh/tpM1Sru/fP0bKwqEdkZKEkObyowrbofjsbDg83d/OetCLlo+Pcc0\n90NyX9SvGRa0WsmdGNwOx2NhepS0v+z74SPAm/VS4HCrxOF4LMxeMs9kFQjtTeMSGNoUUFxxOxyP\nhdmHb2DXrVYJaU9fq6kacjMGtwt4+ViYHY5C7jp6Gr1fXmqa2/nCQFSoIIX/AqJyYnCTY9nhKKTv\nKrtf68sx9a5OQXlt8i4GNzmWzg55P+w8htummG+7yn1sChYGNzmWrqOQvqvsh3o3x9/K8WGwHbZ7\nyFkY3ORYwT4K+VnaXjw5Y71prryrbDts95Dz8DggOVYwj0JGj5xtCu1Xb40NyNYIr3ylsuCKmxwr\nGEchH/hwNeZs/Nk0F8i9bF75SmXB4CZHs/IopO9e9rQ/x6NPq3oBfQ1e+UplweAm8tHp+YU4cvK8\nac6qEyMjEmJMe9wAr3ylkjG4ifJdyMlF89HmplDzH+uBlvWqW/aavPKVyoLBTQS9TaG8fOUrlQ2D\nmzzt+NlsxD433zS35plrUadqJU0VEZWMwU2exdar5FQMbvKcwppCbZswAJVCeVkDOQODmzzFd5Ud\nXjEEm8cnaqqGqGwY3OQJ3+04ijumpprmdk0cCBG2XiXnYXCT6/musnu0jMAH93TWVA1R+TG4ybX+\n830GnvniR9McP3wkN2Bwkyv5rrIf7tMcT/Tn1YjkDgxucpXkmRswfeUe0xxX2eQ2DG5yDd9V9uu3\nx+H62IaaqiGyDoObHC/xtWXY8vNJ0xxX2eRmDG5yLKUUmiR/bZr7Ylg3xDaupakiouBgcJNlrLyX\nYs9JS7D72BnTHFfZ5BUMbrKEVfdSPJedg1bPzDXNrX66Hy6rVrnsxRI5DIObLFHcvRTLGtxsCkWU\nh8FNlgjkvRSPnDyPTs8vNM1tGZ+IMJ8bBRN5RYnBLSKNAXwAoD6AXABTlFKTrS6MnC1Q91L0XWU3\ni6iKRU/0Kk9pRI7nTx/LCwCeUEq1BtAFwDARudLassjpRiTEINxnRVyaeylu/flkgdDeNXEgQ5sI\nfqy4lVIHARzM//FJEdkMIBLAJotrIwcrz70UfQP7hrhIvHprB0vqJHIiUUr5/2CRaADLALRVSp3w\n+bmhAIYCQFRUVMfdu3cHrkryhCVbD+Pud1eZ5vjhI3mFiKxWSsX781i/P5wUkWoA/gvgUd/QBgCl\n1BQAUwAgPj7e/78NiFBwlf1UYis80KuZpmqI7M2v4BaRisgL7Y+UUjOtLYm85L1vd2Hs/8y7blxl\nExXPn1MlAuAdAJuVUq9YXxJ5he8q++07OyKxbX1N1RA5hz8r7m4AhgDYICJr8+dGKaW+LubXEBVp\n9KwN+CiVrVeJysqfUyUrAPDGfFRuhTWF+t9D3dGuUU1NFRE5E6+cpKAY9MYKrNt33DTHVTZR2TC4\nyVLZObloMXqOae6H5L6oXzNMU0VEzsfgJsuwKRSRNRjcFHDHz2Qjdtx809yPzyWgamX+cSMKBH4n\nUUD5rrLrVK2ENc9cq6kaIndicPvJyru5uEHG0dPo9fJS09xPLwxESAV3HEji15/shMHtB6vu5uIW\nvqvsPq0ux7Q/d9JUTeDx6092409bV88r7m4uXrbpwIkCoR1ZKxzXxzbUVJE1+PUnu+GK2w+BvJuL\nWxR2YgRw52qUX3+yG664/VDUXVtKezcXN1i69XCRoX2R21aj/PqT3TC4/VDeu7m4RfTI2fjzJf2y\nP7inc5G9ENy0GuXXn+yGWyV+KM/dXAJB94mGj1P3YNSsDaa5ixfSBOreknam++tP5KtUd8DxV3x8\nvEpLSwv483qR74kGIG+1N/HGdkEJDt9tkTnDr0HrBjVsUx+RW5TmDjjcKrE5XScaJn69uUBoZ6Qk\nmUIbyFuNTryxHSJrhUOQd6qEoU1kLW6V2FywTzTk5io0HWVuvVpSU6jBcZEMaqIgYnDbXDD3kO99\nbxUWbTlsjGuEhWL92ISAvw4RlQ+D2+ZGJMQUuoccyBMNZ7Ny0PrZuaa5jc8loBqbQhHZEr8zbc7q\nEw3dUhabVvRXN6mDT+/vGpDnJiJrMLgdwIo95KOnziN+wkLT3I7nByA0hJ9XE9kdg9uDfE+L3Nkl\nChMGt9NUDRGVFoPbQ3YcPoV+r3xjmts1cSBE3NF6lcgrGNwe4bvKfva6K3FP9yaaqiGi8mBwu1zq\nzmO4dcoPpjne95HI2Rjcl9DdEyTQfFfZ/xrSEQlt6muqhogChcGdz013Ofk8fT8e/XStaY6rbCL3\nYHDnK64niJOC23eV/fmwbujQuJamaojICgzufE6/y8nri7bjlQXbTHNcZRO5k22CW/f+slP7Siul\n0CTZ3BRq+ZO90bhOFU0VEZHVbHGZ3MX95f2ZZ6Hw2/7y5+n7g1aDE+9y8ugn6QVCOyMliaFN5HK2\nWHHbYX/ZSXc5ybqQi5ZPzzHNrXu2P2pWqaipIiIKJlsEt132l53QV3rA5OXYfPCEMW7doAbmDL9G\nY0VEFGy2CG6n7i8H0/Ez2YgdN980t23CAFQKtcVuFxEFkS2+6524vxxM932QZgrtwR0aIiMliaFN\n5FG2WHE7aX85mAprvcqmUERki+AGnLG/HEyJry3Dlp9PGuO3/ngVBrRroLEiIrIL2wQ35ck4ehq9\nXl5qnuOFNER0iRKDW0SmAbgOwGGlVFvrS/KulqPnICsn1xh/dn9XdG5SR2NFRGRH/ny69R6ARIvr\n8LS1ezMRPXK2KbQzUpIY2kRUqBJX3EqpZSISbX0p3uTbFGrBYz3Qol51TdUQkRNwj1uTxVsO4Z73\n0oxxo9rhWPFUH40VEZFTBCy4RWQogKEAEBUVFaindZ3CmkKljuqLejXCNFVERE4TsCs4lFJTlFLx\nSqn4iIiIQD2tq3y6ao8ptK9pURcZKUkMbSIqFW6VBEFOrkKzUeZV9vqx/VEjjE2hiKj0Slxxi8h0\nAN8DiBGRfSJyr/VlucerC7aZQvuPV0chIyWJoU1EZebPqZLbg1GI25zLzkGrZ+aa5tgUiogCgVsl\nFnj8s7WYuea3m0A8ldgKD/RqprEiInITBncAZZ7JQodxC0xzO18YiAoV2BSKiAKHwR0gN7/9HVZl\n/GqMX701FjfENdJYERG5FYO7nPb9egbdX1ximmNTKCKyEoO7HK4avwC/nM4yxh/eezW6t6irsSIi\n8gIGdxlsOnACA19fbprjKpuIgoXBXUq+TaFmP9IdbRrW1FQNEXkRg9tPG/Ydx+/fWGGMa1epiPRn\n+2usiIi8isHth7Zj5uHU+QvGeMVTvdGodhWNFRGRlzG4i7Fi+1Hc+U6qMf5T1yswbhBvAkREejG4\nC1FY69UNY/ujOvuLEJENMLh9fLnuAB6Znm6MRyTEYFjv5horIiIyY3Dny8lVGDB5GbYdOmXMbZ2Q\niMqhIRqrIiIqiMENYMmWw7j7vVXG+KWb2uOW+MYaKyIiKpqng/v8hRx0nbjYuPqxU3RtfDq0K5tC\nEZGteTa4Z6Xvw2OfrjPG/3uoO9o14oU0RGR/ngvuU+cvoO2YecY4qV0DvHFHHES4yiYiZ/BUcE9b\nsQvjvtpkjBc/0RNNI6pprIiIqPQ8EdzHTp1HxwkLjfFdXa/Ac7yQhogcyvXB/ff5W/GPxTuM8ffJ\nfdCgZrjGioiIyse1wb0/8yy6pSw2xo9f2xKP9G2hsSIiosBwZXAnz1yP6Sv3GuP0Z65F7aqVNFZE\nRBQ4rgruHYdPot8ry4zx+EFtMKRrtL6CiIgs4IrgVkrhvg/SsHDzYQBAaAXB+rH9UaWSK357REQm\njk+2tXszMfjNb43xP26Pw+9jG2qsiIjIWo4N7txchRve+g7r9mYCAOrXCMOyJ3ujUmgFzZUREVnL\nkcG9fPsRDHlnpTF+/57O6NkyQmNFRETB46jgzrqQi56TluDg8XMAgPaNamLWg90QwqZQROQhjgnu\n2esPYtjHa4zxzAd/h6uiamusiIhID9sH95msC4h9bj6ycxQAoG+ryzH1rng2hSIiz7J1cH+Uuhuj\nZ200xvMf64GW9aprrIiISD9bBnfmmSx0GLfAGN8a3xgv3tReY0VERPZhu+B+Y/F2vDx/mzFe8VRv\nNKpdRWNFRET2YqvgfnPJDiO0H+zVDE8mttJcERGR/dgquDteURvxV9TG20M6om61yrrLISKyJVsF\nd5eml2HGA7/TXQYRka3x+nAiIofxK7hFJFFEtorIDhEZaXVRRERUtBKDW0RCALwJYACAKwHcLiJX\nWl0YEREVzp8Vd2cAO5RSO5VSWQA+ATDI2rKIiKgo/gR3JIC9l4z35c8REZEG/gR3YU1BVIEHiQwV\nkTQRSTty5Ej5KyMiokL5E9z7ADS+ZNwIwAHfBymlpiil4pVS8RER7I1NRGQVf4J7FYAWItJERCoB\nuA3Al9aWRURERRGlCux6FHyQyEAArwEIATBNKfV8CY8/AmB3CU9bF8BRP+v0Gr43heP7UjS+N4Vz\n0vtyhVLKr+0Kv4LbCiKSppSK1/LiNsf3pnB8X4rG96Zwbn1feOUkEZHDMLiJiBxGZ3BP0fjadsf3\npnB8X4rG96ZwrnxftO1xExFR2XCrhIjIYYIe3CLSWESWiMhmEflRRIYHuwY7E5EQEUkXka9012In\nIlJLRGaIyJb8PztddddkByLyWP730UYRmS4iYbpr0kVEponIYRHZeMlcHRFZICLb8/9fW2eNgaJj\nxX0BwBNKqdYAugAYxm6DJsMBbNZdhA1NBjBXKdUKQCz4HkFEIgE8AiBeKdUWeddZ3Ka3Kq3eA5Do\nMzcSwCKlVAsAi/LHjhf04FZKHVRKrcn/8UnkfQOyaRUAEWkEIAnAVN212ImI1ADQA8A7AKCUylJK\nZeqtyjZCAYSLSCiAKiikHYVXKKWWAfjFZ3oQgPfzf/w+gMFBLcoiWve4RSQaQByAVJ112MhrAJ4E\nkKu7EJtpCuAIgHfzt5GmikhV3UXpppTaD+BlAHsAHARwXCk1X29VtlNPKXUQyFs0Arhccz0BoS24\nRaQagP8CeFQpdUJXHXYhItcBOKyUWq27FhsKBXAVgLeUUnEATsMl/+Qtj/z92kEAmgBoCKCqiNyp\ntyoKBi3BLSIVkRfaHymlZuqowYa6AbheRDKQd7OKPiLyod6SbGMfgH1KqYv/MpuBvCD3un4Adiml\njiilsgHMBMC7bZsdEpEGAJD//8Oa6wkIHadKBHl7lZuVUq8E+/XtSimVrJRqpJSKRt4HTIuVUlw9\nAVBK/Qxgr4jE5E/1BbBJY0l2sQdAFxGpkv991Rf80NbXlwDuyv/xXQC+0FhLwIRqeM1uAIYA2CAi\na/PnRimlvtZQCznHwwA+ym8tvBPA3Zrr0U4plSoiMwCsQd5prXS49EpBf4jIdAC9ANQVkX0AxgBI\nAfCZiNyLvL/obtZXYeDwykkiIofhlZNERA7D4CYichgGNxGRwzC4iYgchsFNROQwDG4iIodhcBMR\nOQyDm4jIYf4fjMxC1EyTnDcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa3e7b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 将回归线展示出来\n",
    "def later_plot(data, label, yHat):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)  # add_subplot(349)函数的参数的意思是，将画布分成3行4列图像画在从左到右从上到下第9块\n",
    "    ax.scatter([data[:].flatten()],[label.T[:].flatten()])  # scatter 的x是 features，y是 label\n",
    "    xCopy = data.copy()\n",
    "    xCopy.sort()\n",
    "    ax.plot(xCopy[:],yHat)\n",
    "    plt.show()\n",
    "\n",
    "later_plot(x_train, y_train, predict_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2、小结\n",
    "ok，到这儿基本上就结束啦。我们使用了 pytorch 实现了简单的线性回归模型，掌握了 pytorch 的一些基本操作，下一节我们将使用 logistic 回归对 MNIST 手写字体数据集做识别。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
