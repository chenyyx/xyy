{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 PyTorch 完成 logistic 回归\n",
    "\n",
    "上一节我们介绍了简单的线性回归，如何在 pytorch 里面用最小二乘法来拟合一些离散的点，这一节我们将开始简单的 logistic 回归，介绍图像分类问题，使用的数据是手写字体数据集 MNIST 。\n",
    "\n",
    "## 1、logistic 回归\n",
    "logistic 回归简单来说和线性回归是一样的，要做的运算同样是 y = w * x + b ，logistic 回归简单的是做二分类问题的，使用 sigmoid 函数将所有的正数和负数都变成 0-1 之间的数，这样就可以用这个数来确定到底属于哪一类，可以简单的认为概率大于 0.5 即为第二类，小于 0.5 为第一类。\n",
    "\n",
    "![sigmoid函数](img/pt_lo_1.png)\n",
    "\n",
    "而我们这里要做的是多分类的问题，对于每一个数据，我们输出的维数是分类的总数，比如 10 分类，我们输出的就是一个 10 维的向量，然后我们使用另外一个激活函数，softmax ，如下：\n",
    "\n",
    "![softmax](img/pt_lo_2.png)\n",
    "\n",
    "这就是 softmax 函数作用的机制，其实简单的理解就是确定这 10 个数每个数对应的概率有多大，因为这 10 个数有正有负，所以通过指数函数将他们全部变成正数，然后求和，然后这 10 个数每个数都除以这个和，这样就得到了每个类别的概率。\n",
    "\n",
    "## 2、使用 logistic 回归\n",
    "\n",
    "首先我们要导入 torch 里面专门做图形处理的一个库，torchvision ，根据官方安装指南，你在安装 pytorch 的时候 torchvision 也会安装。\n",
    "\n",
    "我们需要使用的是 torchvision.transforms 和 torchvision.datasets 以及 torch.utils.data.DataLoader \n",
    "\n",
    "首先 DataLoader 是导入图片的操作，里面有一些参数，比如 batch_size 和 shuffle 等，默认 load 进去的图片类型是 PIL.Image.open 的类型，如果你不知道 PIL ，简单来说就是一种读取图片的库。\n",
    "\n",
    "torchvision.transforms 里面的操作是对导入的图片做处理，比如可以随机取 (50, 50) 这样的窗框大小，或者随机翻转，或者去中间的 (50, 50) 的窗框大小部分等等，但是里面必须要用的是 transforms.ToTensor() ，这可以将 PIL 的图片类型转换成 tensor ，这样 pytorch 才可以对其做处理\n",
    "\n",
    "torchvision.datasets 里面有很多数据类型，里面有官网处理好的数据，比如我们要使用 MNIST 数据集，可以使用 torchvision.datasets.MNIST() 来得到，还有一个常使用的是 torchvision.datasets.ImageFolder() ，这个可以让我们按文件夹来取图片，和 keras 里面的 flow_from_directory() 类似，具体的可以去看看官方文档的介绍。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1、引入相应的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 引入相应的库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils import data\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2、下载训练数据集 MNIST 手写数字数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 下载得到 MNIST 手写数字数据集\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=False)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义超参数\n",
    "batch_size = 32\n",
    "learning_rate = 1e-3\n",
    "num_epoches = 10\n",
    "\n",
    "# 设置好加载器\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上就是我们对图片数据的读取操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3、构建模型\n",
    "我们之前讲过模型定义的框架，废话不多说，我们直接上代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Logistic_Regression(nn.Module):\n",
    "    # 定义初始化函数\n",
    "    def __init__(self, in_dim, n_class):\n",
    "        super(Logistic_Regression, self).__init__()\n",
    "        # 我们这里的 logistic 使用的是 Linear，也就是 y = kx + b 这种形式\n",
    "        self.logistic = nn.Linear(in_dim, n_class)\n",
    "    # 定义前向传播    \n",
    "    def forward(self, x):\n",
    "        out = self.logistic(x)\n",
    "        return out\n",
    "    \n",
    "model = Logistic_Regression(28*28, 10) # 图片大小是 28x28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们需要向这个模型传入参数，第一个参数定义为数据的维度，第二维度是我们分类的数目。\n",
    "\n",
    "接着我们可以在 gpu 上跑模型，但是呢？我们没有 gpu ，想想就心累。。。\n",
    "\n",
    "首先我们判断一下你是否能在 gpu 上跑，如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available() # 可以在 gpu 上跑的话，就是 True，不可以的话，就是 False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果返回 True 就说明有 gpu 支持。否则，会返回 False ，表示不支持 gpu 。\n",
    "\n",
    "如果可以的话，你就只需要一个命令就可以运行了。如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 我本机上没有装 gpu ，所以就不运行这部分了，如果没有装 gpu 运行的时间会长一些\n",
    "# model = model.cuda()\n",
    "# 或者\n",
    "# model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，接下来是我们进行 loss 和 optimizer 的定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 我们使用 交叉熵 来做 loss 标准\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 使用 随机梯度下降 作为\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们使用的 loss 是交叉熵，是一种处理分类问题的 loss ，optimizer 我们还是使用随机梯度下降。\n",
    "\n",
    "**本来我们使用的 softmax 函数，在代码中显示写出了，但是有大佬指出如下错误：**\n",
    "\n",
    "**out = F.softmax(out)这一行是不需要的，nn.CrossEntropyLoss()本身会自动算softmax，你这样实际上是算了两次softmax，所以准确率会降低一些**\n",
    "\n",
    "所以我们就将原代码中的 softmax() 去掉了。\n",
    "\n",
    "### 2.3、训练模型\n",
    "接下来我们就开始训练了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anacondapy3.6\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "D:\\anacondapy3.6\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss -- tensor(24990.2344)\n",
      "Acc -- tensor(53361)\n",
      "epoch 2\n",
      "**********\n",
      "Loss -- tensor(24728.8574)\n",
      "Acc -- tensor(53422)\n",
      "epoch 3\n",
      "**********\n",
      "Loss -- tensor(24485.3789)\n",
      "Acc -- tensor(53456)\n",
      "epoch 4\n",
      "**********\n",
      "Loss -- tensor(24257.7070)\n",
      "Acc -- tensor(53506)\n",
      "epoch 5\n",
      "**********\n",
      "Loss -- tensor(24046.9590)\n",
      "Acc -- tensor(53558)\n",
      "epoch 6\n",
      "**********\n",
      "Loss -- tensor(23848.0723)\n",
      "Acc -- tensor(53600)\n",
      "epoch 7\n",
      "**********\n",
      "Loss -- tensor(23660.5352)\n",
      "Acc -- tensor(53632)\n",
      "epoch 8\n",
      "**********\n",
      "Loss -- tensor(23483.3887)\n",
      "Acc -- tensor(53682)\n",
      "epoch 9\n",
      "**********\n",
      "Loss -- tensor(23316.9961)\n",
      "Acc -- tensor(53715)\n",
      "epoch 10\n",
      "**********\n",
      "Loss -- tensor(23159.0293)\n",
      "Acc -- tensor(53742)\n"
     ]
    }
   ],
   "source": [
    "# 判断是否使用 gpu\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "for epoch in range(num_epoches):\n",
    "    print('epoch {}'.format(epoch+1))\n",
    "    print('*'*10)\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    for i, data in enumerate(train_loader, 1):\n",
    "        img, label = data\n",
    "        img = img.view(img.size(0), -1)  # 将图片展开成 28x28\n",
    "        if use_gpu:\n",
    "            img = Variable(img).cuda()\n",
    "            label = Variable(label).cuda()\n",
    "        else:\n",
    "            img = Variable(img)\n",
    "            label = Variable(label)\n",
    "        # 向前传播\n",
    "        out = model(img)\n",
    "        loss = criterion(out, label)\n",
    "        running_loss += loss.data[0] * label.size(0)\n",
    "        # torch.max(a,1) 返回每一行中最大值的那个元素，且返回其索引（返回最大元素在这一行的列索引）\n",
    "        _, pred = torch.max(out, 1)\n",
    "        num_correct = (pred == label).sum()\n",
    "        running_acc += num_correct.data[0]\n",
    "        # 向后传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Loss --\", running_loss)\n",
    "    print(\"Acc --\", running_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后我们可以测试模型，过程与训练类似，只是注意要将模型改成测试模式。\n",
    "\n",
    "```python\n",
    "model.eval()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "具体的结果，多久打印一次，以及如何打印都可以自己在 for 循环里设计。\n",
    "\n",
    "## 3、小结\n",
    "这一部分，我们就讲解了如何用 logistic 回归做一个简单的图片分类问题，知道了如何在 gpu 上跑模型，下一节我们介绍如何写简单的卷积神经网络。不了解卷积神经网络的同学可以提前先去了解一下。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
